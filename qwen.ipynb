{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/db/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me a short introduction to large language model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qwen_prompt(prompt):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A large language model is an artificial intelligence (AI) system that can generate human-like text in response to prompts or questions. These models are designed to understand and process natural language input, allowing them to answer questions, provide information, generate creative writing, or perform other tasks requiring human-like communication.\\n\\nThe term \"large\" refers to the size of the model\\'s parameters—typically measured in billions or trillions of parameters—and the computational resources required to train such models. Large language models use advanced algorithms and techniques, including neural networks, to analyze vast amounts of data and learn patterns, enabling them to make accurate predictions and generate coherent responses based on their training data.\\n\\nThese models have been applied across various domains, from language translation and chatbots to virtual assistants and content creation tools. They continue to evolve rapidly as researchers develop new methods for improving performance and scaling up to handle even larger datasets.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_qwen_prompt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class DataFile:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file = open(file_path, mode='r')\n",
    "        self.csv_reader = csv.reader(self.file)\n",
    "        self.header = next(self.csv_reader)\n",
    "        self.make_int = ['overall_rating', 'volleys', 'free_kick_accuracy', 'weight']\n",
    "        if all([m in self.header] for m in self.make_int):\n",
    "            self.players=True\n",
    "            self.change_inds = [i for i in range(len(self.header)) if self.header[i] in self.make_int]\n",
    "        else:\n",
    "            self.players = False\n",
    "    \n",
    "    def get_next_row(self):\n",
    "        try:\n",
    "            row = next(self.csv_reader)\n",
    "            if self.players:\n",
    "                for i in self.change_inds:\n",
    "                    t = row[i]\n",
    "                    row[i] = str(int(float(t)))\n",
    "            return row\n",
    "        except StopIteration:\n",
    "            return None\n",
    "    \n",
    "    def get_header(self):\n",
    "        return self.header\n",
    "    \n",
    "    def reset(self):\n",
    "        self.file.close()\n",
    "        self.file = open(self.file_path, mode='r')\n",
    "        self.csv_reader = csv.reader(self.file)\n",
    "        self.header = next(self.csv_reader)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.file.close()\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, dirty_file_path, clean_file_path) -> None:\n",
    "        self.dirty = DataFile(dirty_file_path)\n",
    "        self.clean = DataFile(clean_file_path)\n",
    "\n",
    "    def get_header(self):\n",
    "        return self.dirty.get_header()\n",
    "\n",
    "    def get_next_row(self):\n",
    "        dirty_row = self.dirty.get_next_row()\n",
    "        clean_row = self.clean.get_next_row()\n",
    "\n",
    "        if dirty_row is None or clean_row is None:\n",
    "            return None\n",
    "        \n",
    "        error_headers = [h_col for d_col, c_col, h_col in zip(dirty_row, clean_row, self.dirty.get_header()) if d_col != c_col]\n",
    "\n",
    "        return (dirty_row, clean_row, error_headers)\n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        self.dirty.reset()\n",
    "        self.clean.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = Dataset(dirty_file_path='new_datasets/players_missing.csv', clean_file_path='new_datasets/players_clean.csv')\n",
    "\n",
    "#header = ms.get_header()\n",
    "\n",
    "#row = ms.get_next_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def __init__(self, run_fn, model_type='qwen2.5-72B-instruct', detection_type=\"column\"):\n",
    "        self.run_fn = run_fn\n",
    "        self.model_type = model_type\n",
    "        self.detection_type = detection_type\n",
    "\n",
    "    def _generate_prompt(self, row, header, dataset_type):\n",
    "        formated_header = '|'.join(header)\n",
    "        formatted_row = '|'.join(row)\n",
    "\n",
    "        prompt = f\"I have tabular data with the following columns {formated_header}. \" \n",
    "        if self.detection_type=='metadata':\n",
    "            prompt += self._get_metadata(dataset_type)\n",
    "        prompt += f\"Detect if there are any errors, typos, or missing entries in the following row: \"\n",
    "        prompt += f\"{formatted_row}. Just report columns with errors.\" \n",
    "\n",
    "        return prompt \n",
    "    \n",
    "    def _get_metadata(self, dataset):\n",
    "        if dataset == 'players':\n",
    "            return self._get_players_metadata()\n",
    "    \n",
    "    def _get_players_metadata(self):\n",
    "        prompt = \"The overall_rating column is an integer between 0 and 100.\"\n",
    "        prompt += \"The preferred_foot column is either right or left.\"\n",
    "        prompt += \"The attacking_work_rate column is one of the following: low, medium, high.\"\n",
    "        prompt += \"The volleys column is an integer between 0 and 100.\"\n",
    "        prompt += \"The free_kick_accuracy column is an integer between 0 and 100.\"\n",
    "        prompt += \"The player_name column is a value like Aaron Hunt or Stephane M'Bia or Sung-Yeung Ki or Suso or Tulio de Melo or Victor Hugo Montano\"\n",
    "        prompt += \"The height column is a float value between 120.0 and 250.0.\"\n",
    "        prompt += \"The weight column is an integer value between 100 and 300.\"\n",
    "        prompt += \"The country column is one of the following values: England, France, Germany, Italy, Spain.\"\n",
    "        prompt += \"The league column is one of the following values: England Premier League, France Ligue 1, Germany 1. Bundesliga, Italy Serie A, kstraklasa,  Spain LIGA BBVA.\"\n",
    "        prompt += \"If the league column is 'England Premier League' then the country must be 'England'.\"\n",
    "        prompt += \"If the league column is 'France Ligue 1' then the country must be 'France'.\"\n",
    "        prompt += \"If the league column is 'Germany 1. Bundesliga' then the country must be 'Germany'.\"\n",
    "        prompt += \"If the league column is 'Italy Serie A' then the country must be 'Italy'.\"\n",
    "        prompt += \"If the league column is 'Spain LIGA BBVA' then the country must be 'Spain'.\"\n",
    "        prompt += \"Only discuss columns with errors. Do NOT mention correct columns. \"\n",
    "        return prompt\n",
    "    \n",
    "    def _get_qwen_split_phrases(self):\n",
    "        return []\n",
    "    \n",
    "    def get_columns_mentioned_in_response(self, res, header):\n",
    "        header = [col.lower() for col in header]\n",
    "\n",
    "        cols = [col for col in header if f\"'{col}'\" in res or f\"\\\"{col}\\\"\" in res or f\" {col} \" in res or f\"*{col}*\" in res or f\"\\n{col} \" in res]\n",
    "\n",
    "        if 'row_id' in cols:\n",
    "            cols.remove('row_id')\n",
    "\n",
    "        return cols\n",
    "    \n",
    "    def help_get_response(self, row, header, dataset_type=\"players\", printres=True):\n",
    "        prompt = self._generate_prompt(row, header, dataset_type)\n",
    "\n",
    "        if 'qwen' in self.model_type:\n",
    "            split_phrases = self._get_qwen_split_phrases()\n",
    "        else:\n",
    "            split_phrases = []\n",
    "        \n",
    "        res= self.run_fn(prompt)\n",
    "        if printres:\n",
    "            print(res)\n",
    "\n",
    "        for phrase in split_phrases:\n",
    "            split_side = 0\n",
    "            if type(phrase) is tuple:\n",
    "                split_side = phrase[1]\n",
    "                phrase = phrase[0]\n",
    "        \n",
    "            if phrase in res:\n",
    "                res = res.split(phrase)[split_side]\n",
    "\n",
    "        errors = self.get_columns_mentioned_in_response(res, header)\n",
    "        if printres:\n",
    "            print(errors)\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_col = Detector(run_qwen_prompt, model_type='qwen2.5-1.5B-Instruct', detection_type='column')\n",
    "\n",
    "#errorsc = detector_col.help_get_response(ms.get_next_row()[0], ms.get_header(), dataset_type=\"players\")\n",
    "\n",
    "#detector_md = Detector(run_qwen_prompt, model_type='qwen2.5-1.5B-Instruct', detection_type='metadata')\n",
    "#errorsm = detector_md.help_get_response(ms.get_next_row()[0], ms.get_header(), dataset_type=\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_md = Detector(run_qwen_prompt, model_type='qwen2.5-1.5B-Instruct', detection_type='metadata')\n",
    "#row = ms.get_next_row()\n",
    "#errorsm = detector_md.help_get_response(row[0], ms.get_header(), dataset_type=\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Evaluate:\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.header = dataset.get_header()\n",
    "    \n",
    "    # precision: correct error detections / total number of error detections\n",
    "    # recall: correct error detections / total number of errors\n",
    "    # f1-score: 2 * (precions * recall) / (precision + recall)\n",
    "\n",
    "    def eval(self, detector, limit=10000, mod=1):\n",
    "        self.dataset.reset()\n",
    "\n",
    "        is_fn = 'fn.csv' in self.dataset.dirty.file_path\n",
    "\n",
    "        num_reported_errors = 0\n",
    "        num_correct_reported_errors = 0\n",
    "        num_errors = 0\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        while i < limit:\n",
    "\n",
    "            r = self.dataset.get_next_row()\n",
    "            if r is None:\n",
    "                break\n",
    "\n",
    "            dirty_row, clean_row, error_columns = r \n",
    "\n",
    "            if error_columns != []:\n",
    "                check = True\n",
    "\n",
    "            num_errors += len(error_columns)\n",
    "\n",
    "            if i % mod == 0:\n",
    "                printres = True\n",
    "            else:\n",
    "                printres = False\n",
    "            reported_error_columns = detector.help_get_response(dirty_row, self.header, printres)\n",
    "\n",
    "            # if is_fn and 'relationship' in error_columns:\n",
    "            #     if 'sex' in reported_error_columns:\n",
    "            #         num_correct_reported_errors += 1\n",
    "            #         num_errors += 1\n",
    "            #     if 'relationship' in reported_error_columns:\n",
    "            #         num_correct_reported_errors += 1\n",
    "            # else:\n",
    "            for col in reported_error_columns:\n",
    "                if col in error_columns:\n",
    "                    # correct error found!\n",
    "                    num_correct_reported_errors += 1\n",
    "            \n",
    "            num_reported_errors += len(reported_error_columns)\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                print(f\"\\t\\t\\t{i}\")\n",
    "                print(f\"\\t\\t\\t\\t{num_errors, num_reported_errors, num_correct_reported_errors}\")\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        precision = 0\n",
    "        if num_reported_errors != 0:\n",
    "            precision = num_correct_reported_errors / num_reported_errors\n",
    "\n",
    "        recall = 0\n",
    "        if num_errors != 0:\n",
    "            recall = num_correct_reported_errors / num_errors\n",
    "\n",
    "        f1 = 0\n",
    "        if precision + recall != 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        scores = {'recall':recall, 'precision':precision, 'f1':f1, 'num_errors': num_errors, 'num_reported_errors': num_reported_errors, 'num_correct_reported_errors':num_correct_reported_errors}\n",
    "\n",
    "        return (num_errors, num_reported_errors, num_correct_reported_errors, scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an error in the \"preferred_foot\" column of the provided row. The correct value should be either \"left\" or \"right\", but it has been entered as \"right\".\n",
      "['preferred_foot']\n",
      "\t\t\t0\n",
      "\t\t\t\t(0, 1, 0)\n",
      "The error in the provided row is:\n",
      "\n",
      "- **preferred_foot**: The value \"right\" should be corrected to either \"left\" or \"both\", as it's not specified which foot he prefers.\n",
      "\n",
      "Here’s the corrected version of the row:\n",
      "```\n",
      "89|70|right|medium|33|25|Aaron Hughes|182.88|154|England|England Premier League\n",
      "```\n",
      "['preferred_foot']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m runner \u001b[38;5;241m=\u001b[39m Evaluate(ms)\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_col\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36mEvaluate.eval\u001b[0;34m(self, detector, limit, mod)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     printres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m reported_error_columns \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhelp_get_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirty_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprintres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# if is_fn and 'relationship' in error_columns:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#     if 'sex' in reported_error_columns:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#         num_correct_reported_errors += 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#         num_correct_reported_errors += 1\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m reported_error_columns:\n",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m, in \u001b[0;36mDetector.help_get_response\u001b[0;34m(self, row, header, dataset_type, printres)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m printres:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(errors)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43merrors\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m, in \u001b[0;36mDetector.help_get_response\u001b[0;34m(self, row, header, dataset_type, printres)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m printres:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(errors)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43merrors\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:990\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_line:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_suspend(thread, step_cmd, original_step_cmd\u001b[38;5;241m=\u001b[39minfo\u001b[38;5;241m.\u001b[39mpydev_original_step_cmd)\n\u001b[0;32m--> 990\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_return:  \u001b[38;5;66;03m# return event\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     back \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:174\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2197\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2194\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2196\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2197\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2199\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2266\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2263\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2264\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2266\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2267\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/miniconda3/envs/db/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runner = Evaluate(ms)\n",
    "output = runner.eval(detector_col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
